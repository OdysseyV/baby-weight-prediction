{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Programming Assignment 2\n",
    "* CSCI-4930/5930 ML Fall 2021  (Be sure to discard which section you are not enrolled)\n",
    "* Author: Odyssey Villagomez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's load the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# First load the dataset into pandas dataframe\n",
    "full_dataset = pd.read_csv('dataset/baby-weights-dataset.csv',delimiter=',')\n",
    "judge_dataset = pd.read_csv('dataset/judge-without-labels.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tasks for everyone (Tasks 1-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 1: \n",
    "Separate the full_dataset into two parts: X and y, where X denotes the input matrix containing only the input (i.e., independent explanatory) variables, and y denotes the target variable containing only the target values for exactly the same number of samples in the given full_dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "original_df = full_dataset.copy()\n",
    "\n",
    "X = full_dataset.drop(columns = ['BWEIGHT'])\n",
    "y = original_df['BWEIGHT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>HISPMOM</th>\n",
       "      <th>HISPDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  \\\n",
       "0  2001    2        1    33    26.0      10    34   12.0      4       2   \n",
       "1  2002    2        2    19    40.0      10    18   11.0     12       1   \n",
       "2  2003    2        1    33    16.0      14    31   16.0     16       2   \n",
       "3  2004    1        1    25    40.0      15    28   12.0     12       3   \n",
       "4  2005    1        2    21    60.0      13    20   12.0     14       2   \n",
       "\n",
       "   BDEAD  TERMS  LOUTCOME  WEEKS  RACEMOM  RACEDAD HISPMOM HISPDAD  CIGNUM  \\\n",
       "0      0      0         1   35.0        1        1       M       M     0.0   \n",
       "1      0      0         9   41.0        1        1       N       N     0.0   \n",
       "2      0      0         1   39.0        1        1       N       N     0.0   \n",
       "3      0      0         1   38.0        8        1       N       N     0.0   \n",
       "4      0      0         1   40.0        2        2       N       N     0.0   \n",
       "\n",
       "   DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  HERPES  HYDRAM  HEMOGLOB  \\\n",
       "0         0       0        0       0         0       0     0.0         0   \n",
       "1         0       0        0       0         0       0     0.0         0   \n",
       "2         0       0        0       0         0       0     0.0         0   \n",
       "3         0       0        0       0         0       0     0.0         0   \n",
       "4         0       0        0       0         0       0     0.0         0   \n",
       "\n",
       "   HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  RENAL  RHSEN  UTERINE  \\\n",
       "0        0        0       0       0        0        0      0      0        0   \n",
       "1        0        0       0       0        0        0      0      0        0   \n",
       "2        0        0       0       0        0        0      0      0        0   \n",
       "3        0        0       0       0        0        0      0      0        0   \n",
       "4        0        1       0       0        0        0      0      0        0   \n",
       "\n",
       "   BWEIGHT  \n",
       "0   4.3750  \n",
       "1   6.9375  \n",
       "2   8.5000  \n",
       "3   8.5000  \n",
       "4   9.0000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>HISPMOM</th>\n",
       "      <th>HISPDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  \\\n",
       "0  2001    2        1    33    26.0      10    34   12.0      4       2   \n",
       "1  2002    2        2    19    40.0      10    18   11.0     12       1   \n",
       "2  2003    2        1    33    16.0      14    31   16.0     16       2   \n",
       "3  2004    1        1    25    40.0      15    28   12.0     12       3   \n",
       "4  2005    1        2    21    60.0      13    20   12.0     14       2   \n",
       "\n",
       "   BDEAD  TERMS  LOUTCOME  WEEKS  RACEMOM  RACEDAD HISPMOM HISPDAD  CIGNUM  \\\n",
       "0      0      0         1   35.0        1        1       M       M     0.0   \n",
       "1      0      0         9   41.0        1        1       N       N     0.0   \n",
       "2      0      0         1   39.0        1        1       N       N     0.0   \n",
       "3      0      0         1   38.0        8        1       N       N     0.0   \n",
       "4      0      0         1   40.0        2        2       N       N     0.0   \n",
       "\n",
       "   DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  HERPES  HYDRAM  HEMOGLOB  \\\n",
       "0         0       0        0       0         0       0     0.0         0   \n",
       "1         0       0        0       0         0       0     0.0         0   \n",
       "2         0       0        0       0         0       0     0.0         0   \n",
       "3         0       0        0       0         0       0     0.0         0   \n",
       "4         0       0        0       0         0       0     0.0         0   \n",
       "\n",
       "   HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  RENAL  RHSEN  UTERINE  \n",
       "0        0        0       0       0        0        0      0      0        0  \n",
       "1        0        0       0       0        0        0      0      0        0  \n",
       "2        0        0       0       0        0        0      0      0        0  \n",
       "3        0        0       0       0        0        0      0      0        0  \n",
       "4        0        1       0       0        0        0      0      0        0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.3750\n",
       "1    6.9375\n",
       "2    8.5000\n",
       "3    8.5000\n",
       "4    9.0000\n",
       "Name: BWEIGHT, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 2:\n",
    "* Given X representing the input matrix from the full_dataset, y being the target vector (the rightmost column of the full_dataset), obtained from Task 1: \n",
    "* randomly split the (X,y) dataset into 75% for training and 25% for testing using the library function from the library [sklearn.model_selection](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) . Please pass to the train_test_split function an additional argument random_state=45931.\n",
    "* Store the 4 splits as X_train, X_test, y_train, y_test respectively.\n",
    "* Save the ID column for X_train and X_test into ID_train and ID_test as list variable.\n",
    "* Now, drop the ID columns from both X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=45931)\n",
    "\n",
    "ID_train = X_train[['ID']]\n",
    "ID_test = X_test[['ID']]\n",
    "\n",
    "X_train = X_train.drop(['ID'], axis=1)\n",
    "X_test = X_test.drop(['ID'], axis=1)\n",
    "\n",
    "y_test = pd.DataFrame(y_test, columns=['BWEIGHT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>HISPMOM</th>\n",
       "      <th>HISPDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16961</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28131</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35114</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85941</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  BDEAD  \\\n",
       "16961    1        1    36    50.0      16    32   12.0     13       3      0   \n",
       "28131    2        2    23    50.0      13    20   12.0     15       2      0   \n",
       "35114    1        1    26    38.0      11    21   12.0     13       1      0   \n",
       "85941    1        2    22    20.0      10    19   12.0     12       1      0   \n",
       "26819    2        1    35    30.0      13    30   16.0     17       3      0   \n",
       "\n",
       "       TERMS  LOUTCOME  WEEKS  RACEMOM  RACEDAD HISPMOM HISPDAD  CIGNUM  \\\n",
       "16961      0         1   38.0        1        1       N       N     0.0   \n",
       "28131      0         1   41.0        2        2       N       N     0.0   \n",
       "35114      0         9   40.0        1        1       N       N     0.0   \n",
       "85941      0         9   40.0        1        1       N       N     0.0   \n",
       "26819      0         1   39.0        1        1       N       N     0.0   \n",
       "\n",
       "       DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  HERPES  HYDRAM  HEMOGLOB  \\\n",
       "16961         0       0        0       0         0       0     0.0         0   \n",
       "28131         0       1        0       0         0       0     0.0         0   \n",
       "35114         0       0        0       0         0       0     0.0         0   \n",
       "85941         0       0        0       0         0       0     0.0         0   \n",
       "26819         0       0        0       0         0       0     0.0         0   \n",
       "\n",
       "       HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  RENAL  RHSEN  \\\n",
       "16961        0        0       0       0        1        0      0      0   \n",
       "28131        0        0       0       0        0        0      0      0   \n",
       "35114        0        1       0       0        0        0      0      0   \n",
       "85941        0        0       0       0        0        0      0      0   \n",
       "26819        0        0       0       0        0        0      0      0   \n",
       "\n",
       "       UTERINE  \n",
       "16961        0  \n",
       "28131        0  \n",
       "35114        0  \n",
       "85941        0  \n",
       "26819        0  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>HISPMOM</th>\n",
       "      <th>HISPDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40925</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46370</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78590</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101381</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43749</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  BDEAD  \\\n",
       "40925     2        1    30    33.0      16    29   16.0     17       1      0   \n",
       "46370     2        1    23    20.0      10    22   12.0     15       2      0   \n",
       "78590     1        2    24    34.0      12    21   10.0     14       2      0   \n",
       "101381    2        1    32    16.0      15    28   12.0     13       2      0   \n",
       "43749     2        1    26    30.0       7    30   16.0     16       4      0   \n",
       "\n",
       "        TERMS  LOUTCOME  WEEKS  RACEMOM  RACEDAD HISPMOM HISPDAD  CIGNUM  \\\n",
       "40925       0         9   39.0        1        1       N       N     0.0   \n",
       "46370       0         1   39.0        2        2       N       N     0.0   \n",
       "78590       0         1   38.0        2        2       N       N     0.0   \n",
       "101381      0         1   39.0        1        1       N       N     0.0   \n",
       "43749       1         2   39.0        1        1       N       N     0.0   \n",
       "\n",
       "        DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  HERPES  HYDRAM  HEMOGLOB  \\\n",
       "40925          0       0        0       0         0       0     0.0         0   \n",
       "46370          0       0        0       0         0       0     0.0         0   \n",
       "78590          0       0        0       0         0       0     0.0         0   \n",
       "101381         0       0        0       0         0       0     0.0         0   \n",
       "43749          0       1        0       0         0       0     0.0         0   \n",
       "\n",
       "        HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  RENAL  RHSEN  \\\n",
       "40925         0        0       0       0        0        0      0      0   \n",
       "46370         1        0       0       0        0        0      0      0   \n",
       "78590         0        0       0       0        0        0      0      0   \n",
       "101381        0        0       0       0        0        0      0      0   \n",
       "43749         0        0       0       0        0        0      0      0   \n",
       "\n",
       "        UTERINE  \n",
       "40925         0  \n",
       "46370         0  \n",
       "78590         0  \n",
       "101381        0  \n",
       "43749         0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 3:\n",
    "Compute mean, stdev, min, max, 25% percentile, median and 75% percentile of BWEIGHT target variable (i.e, the target y) in the training set (i.e., y_train), and print the computed values as a numpy array containing these 7 results (respectively).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.256997863247864, 1.3300584336292791, 0.3125, 13.0625, 6.625, 7.375, 8.0625]\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "import statistics as s\n",
    "\n",
    "y_train = pd.DataFrame(y_train)\n",
    "mean = y_train['BWEIGHT'].mean()\n",
    "stdev = s.stdev(y_train['BWEIGHT'])\n",
    "min_val = y_train['BWEIGHT'].min()\n",
    "max_val = y_train['BWEIGHT'].max()\n",
    "twenty_fith = np.percentile(y_train['BWEIGHT'], 25) \n",
    "median =  y_train['BWEIGHT'].median()\n",
    "seventy_fith = np.percentile(y_train['BWEIGHT'], 75) \n",
    "\n",
    "results_array =[mean, stdev, min_val, max_val, twenty_fith, median, seventy_fith]\n",
    "print(results_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 4: \n",
    "Given the training dataset (X_train, y_train), save as X_train_ohe after replacing all the non-numeric variables (i.e., categorical variables) with numeric encoding. Please consider using the \"One-hot encoding\" scheme i.e., introducing dummy variables. A brief description of the scheme can be found in the [DUMMY-variables.note.txt](DUMMY-variables.note.txt) file\n",
    "* Use the same encoder to perform onehotencoding on the X_test dataset and save the result as X_test_ohe.\n",
    "* Print the column names of X_test_ohe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = X_train.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = X_train.columns[categorical_feature_mask].tolist()\n",
    "cat_columns_idx = [X_train.columns.get_loc(col) \n",
    "                   for col in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_cols),\n",
    "    remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Odyss\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_ohe = pd.DataFrame(column_trans.fit_transform(X_train),columns=column_trans.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Odyss\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_test_ohe = pd.DataFrame(column_trans.transform(X_test),columns=column_trans.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onehotencoder__x0_C', 'onehotencoder__x0_M', 'onehotencoder__x0_N',\n",
       "       'onehotencoder__x0_O', 'onehotencoder__x0_P', 'onehotencoder__x0_S',\n",
       "       'onehotencoder__x0_U', 'onehotencoder__x1_C', 'onehotencoder__x1_M',\n",
       "       'onehotencoder__x1_N', 'onehotencoder__x1_O', 'onehotencoder__x1_P',\n",
       "       'onehotencoder__x1_S', 'onehotencoder__x1_U', 'SEX', 'MARITAL', 'FAGE',\n",
       "       'GAINED', 'VISITS', 'MAGE', 'FEDUC', 'MEDUC', 'TOTALP', 'BDEAD',\n",
       "       'TERMS', 'LOUTCOME', 'WEEKS', 'RACEMOM', 'RACEDAD', 'CIGNUM',\n",
       "       'DRINKNUM', 'ANEMIA', 'CARDIAC', 'ACLUNG', 'DIABETES', 'HERPES',\n",
       "       'HYDRAM', 'HEMOGLOB', 'HYPERCH', 'HYPERPR', 'ECLAMP', 'CERVIX',\n",
       "       'PINFANT', 'PRETERM', 'RENAL', 'RHSEN', 'UTERINE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ['HISPMOM', 'HISPDAD']\n"
     ]
    }
   ],
   "source": [
    "print(len(categorical_cols), categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['onehotencoder__x0_C', 'onehotencoder__x0_M', 'onehotencoder__x0_N',\n",
      "       'onehotencoder__x0_O', 'onehotencoder__x0_P', 'onehotencoder__x0_S',\n",
      "       'onehotencoder__x0_U', 'onehotencoder__x1_C', 'onehotencoder__x1_M',\n",
      "       'onehotencoder__x1_N', 'onehotencoder__x1_O', 'onehotencoder__x1_P',\n",
      "       'onehotencoder__x1_S', 'onehotencoder__x1_U', 'SEX', 'MARITAL', 'FAGE',\n",
      "       'GAINED', 'VISITS', 'MAGE', 'FEDUC', 'MEDUC', 'TOTALP', 'BDEAD',\n",
      "       'TERMS', 'LOUTCOME', 'WEEKS', 'RACEMOM', 'RACEDAD', 'CIGNUM',\n",
      "       'DRINKNUM', 'ANEMIA', 'CARDIAC', 'ACLUNG', 'DIABETES', 'HERPES',\n",
      "       'HYDRAM', 'HEMOGLOB', 'HYPERCH', 'HYPERPR', 'ECLAMP', 'CERVIX',\n",
      "       'PINFANT', 'PRETERM', 'RENAL', 'RHSEN', 'UTERINE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "print(X_test_ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>onehotencoder__x1_P</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>onehotencoder__x1_U</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onehotencoder__x0_C  onehotencoder__x0_M  onehotencoder__x0_N  \\\n",
       "0                  0.0                  0.0                  1.0   \n",
       "1                  0.0                  0.0                  1.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  0.0                  0.0                  1.0   \n",
       "4                  0.0                  0.0                  1.0   \n",
       "\n",
       "   onehotencoder__x0_O  onehotencoder__x0_P  onehotencoder__x0_S  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x0_U  onehotencoder__x1_C  onehotencoder__x1_M  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x1_N  onehotencoder__x1_O  onehotencoder__x1_P  \\\n",
       "0                  1.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  1.0                  0.0                  0.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x1_S  onehotencoder__x1_U  SEX  MARITAL  FAGE  GAINED  \\\n",
       "0                  0.0                  0.0  2.0      1.0  30.0    33.0   \n",
       "1                  0.0                  0.0  2.0      1.0  23.0    20.0   \n",
       "2                  0.0                  0.0  1.0      2.0  24.0    34.0   \n",
       "3                  0.0                  0.0  2.0      1.0  32.0    16.0   \n",
       "4                  0.0                  0.0  2.0      1.0  26.0    30.0   \n",
       "\n",
       "   VISITS  MAGE  FEDUC  MEDUC  TOTALP  BDEAD  TERMS  LOUTCOME  WEEKS  RACEMOM  \\\n",
       "0    16.0  29.0   16.0   17.0     1.0    0.0    0.0       9.0   39.0      1.0   \n",
       "1    10.0  22.0   12.0   15.0     2.0    0.0    0.0       1.0   39.0      2.0   \n",
       "2    12.0  21.0   10.0   14.0     2.0    0.0    0.0       1.0   38.0      2.0   \n",
       "3    15.0  28.0   12.0   13.0     2.0    0.0    0.0       1.0   39.0      1.0   \n",
       "4     7.0  30.0   16.0   16.0     4.0    0.0    1.0       2.0   39.0      1.0   \n",
       "\n",
       "   RACEDAD  CIGNUM  DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  HERPES  \\\n",
       "0      1.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "1      2.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "2      2.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "3      1.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "4      1.0     0.0       0.0     1.0      0.0     0.0       0.0     0.0   \n",
       "\n",
       "   HYDRAM  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  \\\n",
       "0     0.0       0.0      0.0      0.0     0.0     0.0      0.0      0.0   \n",
       "1     0.0       0.0      1.0      0.0     0.0     0.0      0.0      0.0   \n",
       "2     0.0       0.0      0.0      0.0     0.0     0.0      0.0      0.0   \n",
       "3     0.0       0.0      0.0      0.0     0.0     0.0      0.0      0.0   \n",
       "4     0.0       0.0      0.0      0.0     0.0     0.0      0.0      0.0   \n",
       "\n",
       "   RENAL  RHSEN  UTERINE  \n",
       "0    0.0    0.0      0.0  \n",
       "1    0.0    0.0      0.0  \n",
       "2    0.0    0.0      0.0  \n",
       "3    0.0    0.0      0.0  \n",
       "4    0.0    0.0      0.0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "X_test_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 5: \n",
    "* Given the X_train_ohe (Onehot encoded Pandas Dataframe from Task 4), check if there are missing values, and if yes, count how many, and impute the missing values with corresponding mean values. \n",
    "* Finally, print the counting result as a Pandas dataframe named \"missing_counts\" having 2 columns {variable_name,num_of_missing_values).  Please make sure that the result lists all the input variables in the given dataset. \n",
    "* Now, impute the missing values by mean of the respective variable and save the revised dataframe as X_train_ohe_imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehotencoder__x0_C    0\n",
      "onehotencoder__x0_M    0\n",
      "onehotencoder__x0_N    0\n",
      "onehotencoder__x0_O    0\n",
      "onehotencoder__x0_P    0\n",
      "onehotencoder__x0_S    0\n",
      "onehotencoder__x0_U    0\n",
      "onehotencoder__x1_C    0\n",
      "onehotencoder__x1_M    0\n",
      "onehotencoder__x1_N    0\n",
      "onehotencoder__x1_O    0\n",
      "onehotencoder__x1_P    0\n",
      "onehotencoder__x1_S    0\n",
      "onehotencoder__x1_U    0\n",
      "SEX                    0\n",
      "MARITAL                0\n",
      "FAGE                   0\n",
      "GAINED                 1\n",
      "VISITS                 0\n",
      "MAGE                   0\n",
      "FEDUC                  1\n",
      "MEDUC                  0\n",
      "TOTALP                 0\n",
      "BDEAD                  0\n",
      "TERMS                  0\n",
      "LOUTCOME               0\n",
      "WEEKS                  1\n",
      "RACEMOM                0\n",
      "RACEDAD                0\n",
      "CIGNUM                 1\n",
      "DRINKNUM               0\n",
      "ANEMIA                 0\n",
      "CARDIAC                0\n",
      "ACLUNG                 0\n",
      "DIABETES               0\n",
      "HERPES                 0\n",
      "HYDRAM                 1\n",
      "HEMOGLOB               0\n",
      "HYPERCH                0\n",
      "HYPERPR                0\n",
      "ECLAMP                 0\n",
      "CERVIX                 0\n",
      "PINFANT                0\n",
      "PRETERM                0\n",
      "RENAL                  0\n",
      "RHSEN                  0\n",
      "UTERINE                0\n",
      "dtype: int64\n",
      "Columns with missing values:\n",
      "['GAINED', 'FEDUC', 'WEEKS', 'CIGNUM', 'HYDRAM']\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "missing = X_train_ohe.isnull().sum()\n",
    "print(missing)\n",
    "\n",
    "X_train_ohe_imputed = X_train_ohe.copy()\n",
    "missing_cols = []\n",
    "for item in missing.iteritems(): \n",
    "    if item[1] != 0:\n",
    "        #print(item)\n",
    "        missing_cols.append(item[0])\n",
    "        \n",
    "print('Columns with missing values:')\n",
    "print(missing_cols)  \n",
    "\n",
    "for col in missing_cols:\n",
    "    X_train_ohe_imputed[col].fillna(value=(X_train_ohe[col].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>onehotencoder__x1_P</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>onehotencoder__x1_U</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onehotencoder__x0_C  onehotencoder__x0_M  onehotencoder__x0_N  \\\n",
       "0                  0.0                  0.0                  1.0   \n",
       "1                  0.0                  0.0                  1.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  0.0                  0.0                  1.0   \n",
       "4                  0.0                  0.0                  1.0   \n",
       "\n",
       "   onehotencoder__x0_O  onehotencoder__x0_P  onehotencoder__x0_S  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x0_U  onehotencoder__x1_C  onehotencoder__x1_M  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x1_N  onehotencoder__x1_O  onehotencoder__x1_P  \\\n",
       "0                  1.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  1.0                  0.0                  0.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   onehotencoder__x1_S  onehotencoder__x1_U  SEX  MARITAL  FAGE  GAINED  \\\n",
       "0                  0.0                  0.0  1.0      1.0  36.0    50.0   \n",
       "1                  0.0                  0.0  2.0      2.0  23.0    50.0   \n",
       "2                  0.0                  0.0  1.0      1.0  26.0    38.0   \n",
       "3                  0.0                  0.0  1.0      2.0  22.0    20.0   \n",
       "4                  0.0                  0.0  2.0      1.0  35.0    30.0   \n",
       "\n",
       "   VISITS  MAGE  FEDUC  MEDUC  TOTALP  BDEAD  TERMS  LOUTCOME  WEEKS  RACEMOM  \\\n",
       "0    16.0  32.0   12.0   13.0     3.0    0.0    0.0       1.0   38.0      1.0   \n",
       "1    13.0  20.0   12.0   15.0     2.0    0.0    0.0       1.0   41.0      2.0   \n",
       "2    11.0  21.0   12.0   13.0     1.0    0.0    0.0       9.0   40.0      1.0   \n",
       "3    10.0  19.0   12.0   12.0     1.0    0.0    0.0       9.0   40.0      1.0   \n",
       "4    13.0  30.0   16.0   17.0     3.0    0.0    0.0       1.0   39.0      1.0   \n",
       "\n",
       "   RACEDAD  CIGNUM  DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  HERPES  \\\n",
       "0      1.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "1      2.0     0.0       0.0     1.0      0.0     0.0       0.0     0.0   \n",
       "2      1.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "3      1.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "4      1.0     0.0       0.0     0.0      0.0     0.0       0.0     0.0   \n",
       "\n",
       "   HYDRAM  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  \\\n",
       "0     0.0       0.0      0.0      0.0     0.0     0.0      1.0      0.0   \n",
       "1     0.0       0.0      0.0      0.0     0.0     0.0      0.0      0.0   \n",
       "2     0.0       0.0      0.0      1.0     0.0     0.0      0.0      0.0   \n",
       "3     0.0       0.0      0.0      0.0     0.0     0.0      0.0      0.0   \n",
       "4     0.0       0.0      0.0      0.0     0.0     0.0      0.0      0.0   \n",
       "\n",
       "   RENAL  RHSEN  UTERINE  \n",
       "0    0.0    0.0      0.0  \n",
       "1    0.0    0.0      0.0  \n",
       "2    0.0    0.0      0.0  \n",
       "3    0.0    0.0      0.0  \n",
       "4    0.0    0.0      0.0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 6: \n",
    "* Given a X_train_ohe_imputed (Pandas dataframe from Task 5) where all the categorical variables are already replaced with numeric values, print a list of top 20 highly correlated variables with respect to the target variable, and save the result as a Pandas dataframe named top20_df with 2 columns {variable,corr_score}. \n",
    "* Here, the corr_score between a variable x and the target variable y needs to be computed using the Pearson Correlation Coefficient (PCC). Please note, PCC ranges between -1 to +1. PCC score 0 means no correlation, while value towards +1 and -1 represent positive and negative correlations respectively. For instance, PCC=0.8 and PCC=-0.8 tell similar strength positive and negative correlations between the two subject variables.\n",
    "* Please do not include BWEIGHT in the top20_df list of top 20 correlated variable list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#created a function to repeat this for X_test in Task 7\n",
    "def find_top_correlations(X_ohe_imputed, y_df): \n",
    "    correlation_abs = X_ohe_imputed.apply(lambda x: x.corr(y_df['BWEIGHT'])).abs() #convert correlations to abs val to get accurate top 20\n",
    "    \n",
    "    print('Top 20 correlations')\n",
    "    top20_df = correlation_abs.sort_values(ascending=False)\n",
    "    top20_df = top20_df.head(20)\n",
    "    print(top20_df)  \n",
    "    \n",
    "    top20_df = pd.DataFrame(top20_df) #convert to df \n",
    "    \n",
    "    return top20_df\n",
    "\n",
    "def find_top_10correlations(X_ohe_imputed, y_df): \n",
    "    correlation_abs = X_ohe_imputed.apply(lambda x: x.corr(y_df['BWEIGHT'])).abs() #convert correlations to abs val to get accurate top 20\n",
    "    \n",
    "    print('Top 10 correlations')\n",
    "    top10_df = correlation_abs.sort_values(ascending=False)\n",
    "    top10_df = top10_df.head(10)\n",
    "    print(top10_df)  \n",
    "    \n",
    "    top10_df = pd.DataFrame(top10_df) #convert to df \n",
    "    \n",
    "    return top10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 correlations\n",
      "CARDIAC                0.011286\n",
      "CERVIX                 0.010087\n",
      "GAINED                 0.008894\n",
      "onehotencoder__x1_S    0.008514\n",
      "TERMS                  0.008055\n",
      "BDEAD                  0.007951\n",
      "TOTALP                 0.007463\n",
      "HYDRAM                 0.007007\n",
      "onehotencoder__x1_N    0.006962\n",
      "MAGE                   0.006278\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#for graduate assignment \n",
    "top10_df = find_top_10correlations(X_train_ohe_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 correlations\n",
      "CARDIAC                0.011286\n",
      "CERVIX                 0.010087\n",
      "GAINED                 0.008894\n",
      "onehotencoder__x1_S    0.008514\n",
      "TERMS                  0.008055\n",
      "BDEAD                  0.007951\n",
      "TOTALP                 0.007463\n",
      "HYDRAM                 0.007007\n",
      "onehotencoder__x1_N    0.006962\n",
      "MAGE                   0.006278\n",
      "onehotencoder__x1_O    0.006191\n",
      "HERPES                 0.006062\n",
      "FEDUC                  0.005683\n",
      "ACLUNG                 0.005537\n",
      "RACEDAD                0.005357\n",
      "RACEMOM                0.005348\n",
      "onehotencoder__x0_O    0.005264\n",
      "VISITS                 0.005204\n",
      "PINFANT                0.004799\n",
      "UTERINE                0.004468\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top20_df = find_top_correlations(X_train_ohe_imputed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 7: \n",
    "Given the X_train_ohe_imputed (as Pandas dataframe from task 5) and and top20_df (as Pandas Dataframe from Task 6) having 2 columns {variable_name,corr_score} similar to the one you computed in Task 6:\n",
    "* Please save as X_train_t20 keeping only the columns listed in the top20_df dataframe.\n",
    "* Repeat the process for X_test_ohe (obtained from task 4), and save it as X_test_t20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function for task 7 : \n",
    "def getX_t20(top20_df,X_ohe_imputed): \n",
    "    selected_cols = []\n",
    "    \n",
    "    for index in top20_df.iterrows(): \n",
    "        selected_cols.append(index[0])\n",
    "\n",
    "    X_t20 = pd.DataFrame(X_ohe_imputed, columns = selected_cols)  \n",
    "    \n",
    "    return X_t20 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_t20 keeping only the columns listed in the top20_df dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CARDIAC  CERVIX  GAINED  onehotencoder__x1_S  TERMS  BDEAD  TOTALP  HYDRAM  \\\n",
       "0      0.0     0.0    50.0                  0.0    0.0    0.0     3.0     0.0   \n",
       "1      0.0     0.0    50.0                  0.0    0.0    0.0     2.0     0.0   \n",
       "2      0.0     0.0    38.0                  0.0    0.0    0.0     1.0     0.0   \n",
       "3      0.0     0.0    20.0                  0.0    0.0    0.0     1.0     0.0   \n",
       "4      0.0     0.0    30.0                  0.0    0.0    0.0     3.0     0.0   \n",
       "\n",
       "   onehotencoder__x1_N  MAGE  onehotencoder__x1_O  HERPES  FEDUC  ACLUNG  \\\n",
       "0                  1.0  32.0                  0.0     0.0   12.0     0.0   \n",
       "1                  1.0  20.0                  0.0     0.0   12.0     0.0   \n",
       "2                  1.0  21.0                  0.0     0.0   12.0     0.0   \n",
       "3                  1.0  19.0                  0.0     0.0   12.0     0.0   \n",
       "4                  1.0  30.0                  0.0     0.0   16.0     0.0   \n",
       "\n",
       "   RACEDAD  RACEMOM  onehotencoder__x0_O  VISITS  PINFANT  UTERINE  \n",
       "0      1.0      1.0                  0.0    16.0      1.0      0.0  \n",
       "1      2.0      2.0                  0.0    13.0      0.0      0.0  \n",
       "2      1.0      1.0                  0.0    11.0      0.0      0.0  \n",
       "3      1.0      1.0                  0.0    10.0      0.0      0.0  \n",
       "4      1.0      1.0                  0.0    13.0      0.0      0.0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_train_t20 keeping only the columns listed in the top20_df dataframe')\n",
    "X_train_t20 = getX_t20(top20_df,X_train_ohe_imputed)\n",
    "\n",
    "X_train_t20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehotencoder__x0_C    0\n",
      "onehotencoder__x0_M    0\n",
      "onehotencoder__x0_N    0\n",
      "onehotencoder__x0_O    0\n",
      "onehotencoder__x0_P    0\n",
      "onehotencoder__x0_S    0\n",
      "onehotencoder__x0_U    0\n",
      "onehotencoder__x1_C    0\n",
      "onehotencoder__x1_M    0\n",
      "onehotencoder__x1_N    0\n",
      "onehotencoder__x1_O    0\n",
      "onehotencoder__x1_P    0\n",
      "onehotencoder__x1_S    0\n",
      "onehotencoder__x1_U    0\n",
      "SEX                    0\n",
      "MARITAL                0\n",
      "FAGE                   0\n",
      "GAINED                 0\n",
      "VISITS                 0\n",
      "MAGE                   0\n",
      "FEDUC                  0\n",
      "MEDUC                  0\n",
      "TOTALP                 0\n",
      "BDEAD                  0\n",
      "TERMS                  0\n",
      "LOUTCOME               0\n",
      "WEEKS                  0\n",
      "RACEMOM                0\n",
      "RACEDAD                0\n",
      "CIGNUM                 0\n",
      "DRINKNUM               0\n",
      "ANEMIA                 0\n",
      "CARDIAC                0\n",
      "ACLUNG                 0\n",
      "DIABETES               0\n",
      "HERPES                 0\n",
      "HYDRAM                 0\n",
      "HEMOGLOB               0\n",
      "HYPERCH                0\n",
      "HYPERPR                0\n",
      "ECLAMP                 0\n",
      "CERVIX                 0\n",
      "PINFANT                0\n",
      "PRETERM                0\n",
      "RENAL                  0\n",
      "RHSEN                  0\n",
      "UTERINE                0\n",
      "dtype: int64\n",
      "Columns with missing values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Get X_test_ohe_imputed first \n",
    "missing = X_test_ohe.isnull().sum()\n",
    "print(missing)\n",
    "\n",
    "X_test_ohe_imputed = X_test_ohe.copy()\n",
    "\n",
    "missing_cols = []\n",
    "for item in missing.iteritems(): \n",
    "    if item[1] != 0:\n",
    "        #print(item)\n",
    "        missing_cols.append(item[0])\n",
    "        \n",
    "print('Columns with missing values:')\n",
    "print(missing_cols)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for col in missing_cols:\n",
    "    value = X_test_ohe[col].mean()\n",
    "    X_test_ohe_imputed[col].fillna(value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>onehotencoder__x1_P</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>onehotencoder__x1_U</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25350 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       onehotencoder__x0_C  onehotencoder__x0_M  onehotencoder__x0_N  \\\n",
       "0                      0.0                  0.0                  1.0   \n",
       "1                      0.0                  0.0                  1.0   \n",
       "2                      0.0                  0.0                  1.0   \n",
       "3                      0.0                  0.0                  1.0   \n",
       "4                      0.0                  0.0                  1.0   \n",
       "...                    ...                  ...                  ...   \n",
       "25345                  0.0                  0.0                  1.0   \n",
       "25346                  0.0                  1.0                  0.0   \n",
       "25347                  0.0                  1.0                  0.0   \n",
       "25348                  0.0                  0.0                  1.0   \n",
       "25349                  0.0                  0.0                  1.0   \n",
       "\n",
       "       onehotencoder__x0_O  onehotencoder__x0_P  onehotencoder__x0_S  \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "25345                  0.0                  0.0                  0.0   \n",
       "25346                  0.0                  0.0                  0.0   \n",
       "25347                  0.0                  0.0                  0.0   \n",
       "25348                  0.0                  0.0                  0.0   \n",
       "25349                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x0_U  onehotencoder__x1_C  onehotencoder__x1_M  \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      0.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "25345                  0.0                  0.0                  0.0   \n",
       "25346                  0.0                  0.0                  1.0   \n",
       "25347                  0.0                  0.0                  1.0   \n",
       "25348                  0.0                  0.0                  0.0   \n",
       "25349                  0.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x1_N  onehotencoder__x1_O  onehotencoder__x1_P  \\\n",
       "0                      1.0                  0.0                  0.0   \n",
       "1                      1.0                  0.0                  0.0   \n",
       "2                      1.0                  0.0                  0.0   \n",
       "3                      1.0                  0.0                  0.0   \n",
       "4                      1.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "25345                  1.0                  0.0                  0.0   \n",
       "25346                  0.0                  0.0                  0.0   \n",
       "25347                  0.0                  0.0                  0.0   \n",
       "25348                  1.0                  0.0                  0.0   \n",
       "25349                  1.0                  0.0                  0.0   \n",
       "\n",
       "       onehotencoder__x1_S  onehotencoder__x1_U  SEX  MARITAL  FAGE  GAINED  \\\n",
       "0                      0.0                  0.0  2.0      1.0  30.0    33.0   \n",
       "1                      0.0                  0.0  2.0      1.0  23.0    20.0   \n",
       "2                      0.0                  0.0  1.0      2.0  24.0    34.0   \n",
       "3                      0.0                  0.0  2.0      1.0  32.0    16.0   \n",
       "4                      0.0                  0.0  2.0      1.0  26.0    30.0   \n",
       "...                    ...                  ...  ...      ...   ...     ...   \n",
       "25345                  0.0                  0.0  2.0      1.0  26.0     0.0   \n",
       "25346                  0.0                  0.0  2.0      1.0  33.0    30.0   \n",
       "25347                  0.0                  0.0  2.0      1.0  31.0    28.0   \n",
       "25348                  0.0                  0.0  1.0      1.0  38.0    29.0   \n",
       "25349                  0.0                  0.0  1.0      1.0  37.0    30.0   \n",
       "\n",
       "       VISITS  MAGE  FEDUC  MEDUC  TOTALP  BDEAD  TERMS  LOUTCOME  WEEKS  \\\n",
       "0        16.0  29.0   16.0   17.0     1.0    0.0    0.0       9.0   39.0   \n",
       "1        10.0  22.0   12.0   15.0     2.0    0.0    0.0       1.0   39.0   \n",
       "2        12.0  21.0   10.0   14.0     2.0    0.0    0.0       1.0   38.0   \n",
       "3        15.0  28.0   12.0   13.0     2.0    0.0    0.0       1.0   39.0   \n",
       "4         7.0  30.0   16.0   16.0     4.0    0.0    1.0       2.0   39.0   \n",
       "...       ...   ...    ...    ...     ...    ...    ...       ...    ...   \n",
       "25345     8.0  27.0   13.0   14.0     2.0    0.0    0.0       1.0   40.0   \n",
       "25346    12.0  29.0    8.0    6.0     4.0    0.0    0.0       1.0   39.0   \n",
       "25347     3.0  34.0   10.0   10.0     4.0    0.0    1.0       1.0   41.0   \n",
       "25348    10.0  39.0   17.0   17.0     2.0    0.0    0.0       1.0   36.0   \n",
       "25349    12.0  37.0   16.0   17.0     3.0    0.0    0.0       1.0   38.0   \n",
       "\n",
       "       RACEMOM  RACEDAD  CIGNUM  DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  \\\n",
       "0          1.0      1.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "1          2.0      2.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "2          2.0      2.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "3          1.0      1.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "4          1.0      1.0     0.0       0.0     1.0      0.0     0.0       0.0   \n",
       "...        ...      ...     ...       ...     ...      ...     ...       ...   \n",
       "25345      1.0      1.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "25346      1.0      1.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "25347      1.0      1.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "25348      8.0      1.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "25349      1.0      1.0     0.0       0.0     0.0      0.0     0.0       0.0   \n",
       "\n",
       "       HERPES  HYDRAM  HEMOGLOB  HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  \\\n",
       "0         0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "1         0.0     0.0       0.0      1.0      0.0     0.0     0.0      0.0   \n",
       "2         0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "3         0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "4         0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "...       ...     ...       ...      ...      ...     ...     ...      ...   \n",
       "25345     0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "25346     0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "25347     0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "25348     0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "25349     0.0     0.0       0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "\n",
       "       PRETERM  RENAL  RHSEN  UTERINE  \n",
       "0          0.0    0.0    0.0      0.0  \n",
       "1          0.0    0.0    0.0      0.0  \n",
       "2          0.0    0.0    0.0      0.0  \n",
       "3          0.0    0.0    0.0      0.0  \n",
       "4          0.0    0.0    0.0      0.0  \n",
       "...        ...    ...    ...      ...  \n",
       "25345      0.0    0.0    0.0      0.0  \n",
       "25346      0.0    0.0    0.0      0.0  \n",
       "25347      0.0    0.0    0.0      0.0  \n",
       "25348      0.0    0.0    0.0      0.0  \n",
       "25349      0.0    0.0    0.0      0.0  \n",
       "\n",
       "[25350 rows x 47 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ohe_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CARDIAC', 'CERVIX', 'GAINED', 'onehotencoder__x1_S', 'TERMS', 'BDEAD',\n",
       "       'TOTALP', 'HYDRAM', 'onehotencoder__x1_N', 'MAGE',\n",
       "       'onehotencoder__x1_O', 'HERPES', 'FEDUC', 'ACLUNG', 'RACEDAD',\n",
       "       'RACEMOM', 'onehotencoder__x0_O', 'VISITS', 'PINFANT', 'UTERINE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use top20 correlations, and get data from top 20 cols only \n",
    "X_test_t20 = getX_t20(top20_df,X_test_ohe_imputed)\n",
    "top20_variables = X_test_t20.columns\n",
    "top20_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CARDIAC  CERVIX  GAINED  onehotencoder__x1_S  TERMS  BDEAD  TOTALP  HYDRAM  \\\n",
       "0      0.0     0.0    33.0                  0.0    0.0    0.0     1.0     0.0   \n",
       "1      0.0     0.0    20.0                  0.0    0.0    0.0     2.0     0.0   \n",
       "2      0.0     0.0    34.0                  0.0    0.0    0.0     2.0     0.0   \n",
       "3      0.0     0.0    16.0                  0.0    0.0    0.0     2.0     0.0   \n",
       "4      0.0     0.0    30.0                  0.0    1.0    0.0     4.0     0.0   \n",
       "\n",
       "   onehotencoder__x1_N  MAGE  onehotencoder__x1_O  HERPES  FEDUC  ACLUNG  \\\n",
       "0                  1.0  29.0                  0.0     0.0   16.0     0.0   \n",
       "1                  1.0  22.0                  0.0     0.0   12.0     0.0   \n",
       "2                  1.0  21.0                  0.0     0.0   10.0     0.0   \n",
       "3                  1.0  28.0                  0.0     0.0   12.0     0.0   \n",
       "4                  1.0  30.0                  0.0     0.0   16.0     0.0   \n",
       "\n",
       "   RACEDAD  RACEMOM  onehotencoder__x0_O  VISITS  PINFANT  UTERINE  \n",
       "0      1.0      1.0                  0.0    16.0      0.0      0.0  \n",
       "1      2.0      2.0                  0.0    10.0      0.0      0.0  \n",
       "2      2.0      2.0                  0.0    12.0      0.0      0.0  \n",
       "3      1.0      1.0                  0.0    15.0      0.0      0.0  \n",
       "4      1.0      1.0                  0.0     7.0      0.0      0.0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_t20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 8: \n",
    "* Apply min-max scaling on the training dataset (X_train_t20 obtained from Task 7). Save the result as X_train_scaled_mm.\n",
    "* Then scale the test dataset (X_test_t20 obtained from Task 7) based on the metrics you obtain when you scale the training dataset. Save the result as X_test_scaled_mm.\n",
    "* PLEASE DO NOT SCALE y_train and y_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CARDIAC  CERVIX    GAINED  onehotencoder__x1_S  TERMS  BDEAD    TOTALP  \\\n",
       "0      0.0     0.0  0.510204                  0.0    0.0    0.0  0.105263   \n",
       "1      0.0     0.0  0.510204                  0.0    0.0    0.0  0.052632   \n",
       "2      0.0     0.0  0.387755                  0.0    0.0    0.0  0.000000   \n",
       "3      0.0     0.0  0.204082                  0.0    0.0    0.0  0.000000   \n",
       "4      0.0     0.0  0.306122                  0.0    0.0    0.0  0.105263   \n",
       "\n",
       "   HYDRAM  onehotencoder__x1_N   MAGE  onehotencoder__x1_O  HERPES     FEDUC  \\\n",
       "0     0.0                  1.0  0.475                  0.0     0.0  0.705882   \n",
       "1     0.0                  1.0  0.175                  0.0     0.0  0.705882   \n",
       "2     0.0                  1.0  0.200                  0.0     0.0  0.705882   \n",
       "3     0.0                  1.0  0.150                  0.0     0.0  0.705882   \n",
       "4     0.0                  1.0  0.425                  0.0     0.0  0.941176   \n",
       "\n",
       "   ACLUNG   RACEDAD  RACEMOM  onehotencoder__x0_O    VISITS  PINFANT  UTERINE  \n",
       "0     0.0  0.111111    0.125                  0.0  0.326531      1.0      0.0  \n",
       "1     0.0  0.222222    0.250                  0.0  0.265306      0.0      0.0  \n",
       "2     0.0  0.111111    0.125                  0.0  0.224490      0.0      0.0  \n",
       "3     0.0  0.111111    0.125                  0.0  0.204082      0.0      0.0  \n",
       "4     0.0  0.111111    0.125                  0.0  0.265306      0.0      0.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#from sklearn docuementation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#fit to train set: \n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled_mm = scaler.fit(X_train_t20)\n",
    "\n",
    "#scale\n",
    "X_train_scaled_mm = scaler.transform(X_train_t20)\n",
    "X_train_scaled_mm = pd.DataFrame(X_train_scaled_mm, columns = X_train_t20.columns)\n",
    "X_train_scaled_mm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CARDIAC  CERVIX    GAINED  onehotencoder__x1_S   TERMS  BDEAD    TOTALP  \\\n",
       "0      0.0     0.0  0.336735                  0.0  0.0000    0.0  0.000000   \n",
       "1      0.0     0.0  0.204082                  0.0  0.0000    0.0  0.052632   \n",
       "2      0.0     0.0  0.346939                  0.0  0.0000    0.0  0.052632   \n",
       "3      0.0     0.0  0.163265                  0.0  0.0000    0.0  0.052632   \n",
       "4      0.0     0.0  0.306122                  0.0  0.0625    0.0  0.157895   \n",
       "\n",
       "   HYDRAM  onehotencoder__x1_N   MAGE  onehotencoder__x1_O  HERPES     FEDUC  \\\n",
       "0     0.0                  1.0  0.400                  0.0     0.0  0.941176   \n",
       "1     0.0                  1.0  0.225                  0.0     0.0  0.705882   \n",
       "2     0.0                  1.0  0.200                  0.0     0.0  0.588235   \n",
       "3     0.0                  1.0  0.375                  0.0     0.0  0.705882   \n",
       "4     0.0                  1.0  0.425                  0.0     0.0  0.941176   \n",
       "\n",
       "   ACLUNG   RACEDAD  RACEMOM  onehotencoder__x0_O    VISITS  PINFANT  UTERINE  \n",
       "0     0.0  0.111111    0.125                  0.0  0.326531      0.0      0.0  \n",
       "1     0.0  0.222222    0.250                  0.0  0.204082      0.0      0.0  \n",
       "2     0.0  0.222222    0.250                  0.0  0.244898      0.0      0.0  \n",
       "3     0.0  0.111111    0.125                  0.0  0.306122      0.0      0.0  \n",
       "4     0.0  0.111111    0.125                  0.0  0.142857      0.0      0.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_mm = scaler.transform(X_test_t20)\n",
    "X_test_scaled_mm = pd.DataFrame(X_test_scaled_mm, columns = X_test_t20.columns)\n",
    "X_test_scaled_mm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 9: \n",
    "* Apply standardization (i.e., normalization) scaling on the training dataset (X_train_t20 obtained from Task 7). Save the result as X_train_scaled_std.\n",
    "* Then scale the test dataset (X_test_t20 obtained from Task 7) based on the metrics you obtain when you scale the training dataset. Save the result as X_test_scaled_std.\n",
    "* PLEASE DO NOT SCALE y_train and y_test.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065208</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>1.453173</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>-0.46241</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>0.422206</td>\n",
       "      <td>-0.123089</td>\n",
       "      <td>0.450216</td>\n",
       "      <td>0.715158</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.11402</td>\n",
       "      <td>-0.315860</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>-0.352703</td>\n",
       "      <td>-0.338693</td>\n",
       "      <td>-0.036827</td>\n",
       "      <td>0.951586</td>\n",
       "      <td>13.034526</td>\n",
       "      <td>-0.058231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.065208</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>1.453173</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>-0.46241</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.249694</td>\n",
       "      <td>-0.123089</td>\n",
       "      <td>0.450216</td>\n",
       "      <td>-1.297712</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.11402</td>\n",
       "      <td>-0.315860</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>0.446721</td>\n",
       "      <td>0.426968</td>\n",
       "      <td>-0.036827</td>\n",
       "      <td>0.148920</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.058231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065208</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>0.570368</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>-0.46241</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.921595</td>\n",
       "      <td>-0.123089</td>\n",
       "      <td>0.450216</td>\n",
       "      <td>-1.129973</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.11402</td>\n",
       "      <td>-0.315860</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>-0.352703</td>\n",
       "      <td>-0.338693</td>\n",
       "      <td>-0.036827</td>\n",
       "      <td>-0.386191</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.058231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.065208</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.753839</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>-0.46241</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>-0.921595</td>\n",
       "      <td>-0.123089</td>\n",
       "      <td>0.450216</td>\n",
       "      <td>-1.465452</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.11402</td>\n",
       "      <td>-0.315860</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>-0.352703</td>\n",
       "      <td>-0.338693</td>\n",
       "      <td>-0.036827</td>\n",
       "      <td>-0.653746</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.058231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.065208</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>-0.46241</td>\n",
       "      <td>-0.106858</td>\n",
       "      <td>0.422206</td>\n",
       "      <td>-0.123089</td>\n",
       "      <td>0.450216</td>\n",
       "      <td>0.379679</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.11402</td>\n",
       "      <td>1.051506</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>-0.352703</td>\n",
       "      <td>-0.338693</td>\n",
       "      <td>-0.036827</td>\n",
       "      <td>0.148920</td>\n",
       "      <td>-0.076719</td>\n",
       "      <td>-0.058231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CARDIAC    CERVIX    GAINED  onehotencoder__x1_S    TERMS     BDEAD  \\\n",
       "0 -0.065208 -0.061977  1.453173            -0.197498 -0.46241 -0.106858   \n",
       "1 -0.065208 -0.061977  1.453173            -0.197498 -0.46241 -0.106858   \n",
       "2 -0.065208 -0.061977  0.570368            -0.197498 -0.46241 -0.106858   \n",
       "3 -0.065208 -0.061977 -0.753839            -0.197498 -0.46241 -0.106858   \n",
       "4 -0.065208 -0.061977 -0.018168            -0.197498 -0.46241 -0.106858   \n",
       "\n",
       "     TOTALP    HYDRAM  onehotencoder__x1_N      MAGE  onehotencoder__x1_O  \\\n",
       "0  0.422206 -0.123089             0.450216  0.715158            -0.032042   \n",
       "1 -0.249694 -0.123089             0.450216 -1.297712            -0.032042   \n",
       "2 -0.921595 -0.123089             0.450216 -1.129973            -0.032042   \n",
       "3 -0.921595 -0.123089             0.450216 -1.465452            -0.032042   \n",
       "4  0.422206 -0.123089             0.450216  0.379679            -0.032042   \n",
       "\n",
       "    HERPES     FEDUC    ACLUNG   RACEDAD   RACEMOM  onehotencoder__x0_O  \\\n",
       "0 -0.11402 -0.315860 -0.106127 -0.352703 -0.338693            -0.036827   \n",
       "1 -0.11402 -0.315860 -0.106127  0.446721  0.426968            -0.036827   \n",
       "2 -0.11402 -0.315860 -0.106127 -0.352703 -0.338693            -0.036827   \n",
       "3 -0.11402 -0.315860 -0.106127 -0.352703 -0.338693            -0.036827   \n",
       "4 -0.11402  1.051506 -0.106127 -0.352703 -0.338693            -0.036827   \n",
       "\n",
       "     VISITS    PINFANT   UTERINE  \n",
       "0  0.951586  13.034526 -0.058231  \n",
       "1  0.148920  -0.076719 -0.058231  \n",
       "2 -0.386191  -0.076719 -0.058231  \n",
       "3 -0.653746  -0.076719 -0.058231  \n",
       "4  0.148920  -0.076719 -0.058231  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_t20)\n",
    "X_train_scaled_std = scaler.transform(X_train_t20)\n",
    "X_train_scaled_std = pd.DataFrame(X_train_scaled_std, columns = X_train_t20.columns)\n",
    "X_train_scaled_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>0.190676</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.93520</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.212673</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>1.045819</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>-0.35458</td>\n",
       "      <td>-0.338957</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>0.967521</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>-0.759517</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.26671</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>-0.964900</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>0.45990</td>\n",
       "      <td>0.439143</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>-0.652916</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>0.263768</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.26671</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>-1.133124</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>-1.001824</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>0.45990</td>\n",
       "      <td>0.439143</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>-0.112770</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>-1.051884</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.26671</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>-0.35458</td>\n",
       "      <td>-0.338957</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>0.697448</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>0.758899</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>1.07027</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.380898</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>1.045819</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>-0.35458</td>\n",
       "      <td>-0.338957</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>-1.463134</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CARDIAC    CERVIX    GAINED  onehotencoder__x1_S     TERMS     BDEAD  \\\n",
       "0 -0.065714 -0.059021  0.190676             -0.19362 -0.464198 -0.106897   \n",
       "1 -0.065714 -0.059021 -0.759517             -0.19362 -0.464198 -0.106897   \n",
       "2 -0.065714 -0.059021  0.263768             -0.19362 -0.464198 -0.106897   \n",
       "3 -0.065714 -0.059021 -1.051884             -0.19362 -0.464198 -0.106897   \n",
       "4 -0.065714 -0.059021 -0.028599             -0.19362  0.758899 -0.106897   \n",
       "\n",
       "    TOTALP    HYDRAM  onehotencoder__x1_N      MAGE  onehotencoder__x1_O  \\\n",
       "0 -0.93520 -0.120699             0.450829  0.212673            -0.039754   \n",
       "1 -0.26671 -0.120699             0.450829 -0.964900            -0.039754   \n",
       "2 -0.26671 -0.120699             0.450829 -1.133124            -0.039754   \n",
       "3 -0.26671 -0.120699             0.450829  0.044448            -0.039754   \n",
       "4  1.07027 -0.120699             0.450829  0.380898            -0.039754   \n",
       "\n",
       "     HERPES     FEDUC    ACLUNG  RACEDAD   RACEMOM  onehotencoder__x0_O  \\\n",
       "0 -0.113961  1.045819 -0.108322 -0.35458 -0.338957            -0.035552   \n",
       "1 -0.113961 -0.319276 -0.108322  0.45990  0.439143            -0.035552   \n",
       "2 -0.113961 -1.001824 -0.108322  0.45990  0.439143            -0.035552   \n",
       "3 -0.113961 -0.319276 -0.108322 -0.35458 -0.338957            -0.035552   \n",
       "4 -0.113961  1.045819 -0.108322 -0.35458 -0.338957            -0.035552   \n",
       "\n",
       "     VISITS   PINFANT   UTERINE  \n",
       "0  0.967521 -0.072073 -0.060352  \n",
       "1 -0.652916 -0.072073 -0.060352  \n",
       "2 -0.112770 -0.072073 -0.060352  \n",
       "3  0.697448 -0.072073 -0.060352  \n",
       "4 -1.463134 -0.072073 -0.060352  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_test_t20)\n",
    "X_test_scaled_std = scaler.transform(X_test_t20)\n",
    "X_test_scaled_std = pd.DataFrame(X_test_scaled_std, columns = X_test_t20.columns)\n",
    "X_test_scaled_std.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 10: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_closed_form_training** : It fits a linear regression model using the closed-form solution to obtain the coefficients, beta's, as a numpy array of m+1 values (Please recall class lecture), where *m* is the number of variables kept in X_train (the first argument to the function). Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_closed_form_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function.\n",
    "* **RMSE**: It takes two lists: y_test, y_pred, where the first list represents ground truth (i.e., actual) target values for the given samples, and the second list represents a corresponding predicted values for exactly same number of samples in y_test. Compute and return the Root Mean Squared Error (RMSE) of the prediction. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_closed_form_training() function providing X_train_scaled_std, y_train obtained from Task 9, and save the returned results as betas_closed_form,cpu_time_closed_form.\n",
    "* Print betas_closed_form, cpu_time_closed_form\n",
    "* Call linear_regression_closed_form_predict() function providing betas_closed_form,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_closed_form.\n",
    "* Print rmse_closed_form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ones</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>0.190676</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.93520</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.212673</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>1.045819</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>-0.35458</td>\n",
       "      <td>-0.338957</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>0.967521</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>-0.759517</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.26671</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>-0.964900</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>0.45990</td>\n",
       "      <td>0.439143</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>-0.652916</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>0.263768</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.26671</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>-1.133124</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>-1.001824</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>0.45990</td>\n",
       "      <td>0.439143</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>-0.112770</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>-1.051884</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>-0.464198</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>-0.26671</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>-0.35458</td>\n",
       "      <td>-0.338957</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>0.697448</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.065714</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-0.19362</td>\n",
       "      <td>0.758899</td>\n",
       "      <td>-0.106897</td>\n",
       "      <td>1.07027</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.380898</td>\n",
       "      <td>-0.039754</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>1.045819</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>-0.35458</td>\n",
       "      <td>-0.338957</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>-1.463134</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.060352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ones   CARDIAC    CERVIX    GAINED  onehotencoder__x1_S     TERMS  \\\n",
       "0     1 -0.065714 -0.059021  0.190676             -0.19362 -0.464198   \n",
       "1     1 -0.065714 -0.059021 -0.759517             -0.19362 -0.464198   \n",
       "2     1 -0.065714 -0.059021  0.263768             -0.19362 -0.464198   \n",
       "3     1 -0.065714 -0.059021 -1.051884             -0.19362 -0.464198   \n",
       "4     1 -0.065714 -0.059021 -0.028599             -0.19362  0.758899   \n",
       "\n",
       "      BDEAD   TOTALP    HYDRAM  onehotencoder__x1_N      MAGE  \\\n",
       "0 -0.106897 -0.93520 -0.120699             0.450829  0.212673   \n",
       "1 -0.106897 -0.26671 -0.120699             0.450829 -0.964900   \n",
       "2 -0.106897 -0.26671 -0.120699             0.450829 -1.133124   \n",
       "3 -0.106897 -0.26671 -0.120699             0.450829  0.044448   \n",
       "4 -0.106897  1.07027 -0.120699             0.450829  0.380898   \n",
       "\n",
       "   onehotencoder__x1_O    HERPES     FEDUC    ACLUNG  RACEDAD   RACEMOM  \\\n",
       "0            -0.039754 -0.113961  1.045819 -0.108322 -0.35458 -0.338957   \n",
       "1            -0.039754 -0.113961 -0.319276 -0.108322  0.45990  0.439143   \n",
       "2            -0.039754 -0.113961 -1.001824 -0.108322  0.45990  0.439143   \n",
       "3            -0.039754 -0.113961 -0.319276 -0.108322 -0.35458 -0.338957   \n",
       "4            -0.039754 -0.113961  1.045819 -0.108322 -0.35458 -0.338957   \n",
       "\n",
       "   onehotencoder__x0_O    VISITS   PINFANT   UTERINE  \n",
       "0            -0.035552  0.967521 -0.072073 -0.060352  \n",
       "1            -0.035552 -0.652916 -0.072073 -0.060352  \n",
       "2            -0.035552 -0.112770 -0.072073 -0.060352  \n",
       "3            -0.035552  0.697448 -0.072073 -0.060352  \n",
       "4            -0.035552 -1.463134 -0.072073 -0.060352  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add ones to X_train for Beta_0 \n",
    "X_train_scaled_std.insert(loc=0, column='Ones', value =1)\n",
    "X_train_scaled_std.head()\n",
    "\n",
    "X_test_scaled_std.insert(loc=0, column='Ones', value =1)\n",
    "X_test_scaled_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_closed_form_training(X_train, y_train):\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    from time import perf_counter\n",
    "    cpu_time = 0\n",
    "    betas = []\n",
    "    start = perf_counter()\n",
    "\n",
    "    \n",
    "    \n",
    "    #@TODO: Your code goes here\n",
    "\n",
    "    #solve for the minimum Betas using RSS = (X_T*X)(inverse) (X_T*y)\n",
    "    x_inv = inv(np.dot(X_train.T,X_train)) #x_inv = (X_T*X)(inverse)\n",
    "    xTran_y = np.dot(X_train.T, y_train) #xTy = (X_T*y)\n",
    "    RSS = np.dot(x_inv, xTran_y)\n",
    "    betas = RSS    \n",
    "    \n",
    "    #x_inv = inv(X_train.transpose().dot(X_train)).dot(X.transpose().dot(y_train)\n",
    "    end = perf_counter()\n",
    "    cpu_time = end-start\n",
    "    return betas,cpu_time\n",
    "\n",
    "def linear_regression_closed_form_predict(betas, X_test):\n",
    "    y_pred = []\n",
    "        \n",
    "    #@TODO: Your code goes here\n",
    "    \n",
    "    mx = X_test.dot(betas)\n",
    "    y_pred = mx.sum(axis=1)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def RMSE(y_test, y_pred):\n",
    "    #@TODO: Your code goes here\n",
    "\n",
    "    \"\"\"\n",
    "    rmse = -1\n",
    "    N = len(y_test)\n",
    "    \n",
    "    df = y_test['BWEIGHT'].sub(y_pred)    \n",
    "    df = df*df\n",
    "    df = df.sum()\n",
    "    df = df/N\n",
    "    rmse = np.sqrt(df)\n",
    "    \"\"\"\n",
    "    y_test = np.array(y_test).reshape(y_pred.shape)\n",
    "    rmse = np.sqrt(np.mean((y_pred-y_test)**2))\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "betas_closed_form,cpu_time_closed_form = linear_regression_closed_form_training(X_train_scaled_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01863520000006247 [[ 7.25699786e+00]\n",
      " [-2.83940982e-03]\n",
      " [-8.48136490e-02]\n",
      " [ 2.29265886e-01]\n",
      " [-1.54239058e-02]\n",
      " [-9.90196678e-02]\n",
      " [-4.89336224e-02]\n",
      " [ 9.12841296e-02]\n",
      " [-6.40729468e-02]\n",
      " [-8.37555761e-02]\n",
      " [ 6.25343010e-02]\n",
      " [-9.34289363e-03]\n",
      " [ 1.46733218e-03]\n",
      " [ 4.80833085e-02]\n",
      " [-1.23809320e-03]\n",
      " [-6.49515656e-02]\n",
      " [-3.92789299e-02]\n",
      " [-1.86248632e-03]\n",
      " [ 1.51928147e-01]\n",
      " [ 7.82315052e-02]\n",
      " [-4.81151107e-02]]\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "print(cpu_time_closed_form,betas_closed_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = y_test.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "y_pred = linear_regression_closed_form_predict(betas_closed_form,X_test_scaled_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2787745175447585"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "#Compute and return the Root Mean Squared Error (RMSE) of the prediction.\n",
    "rmse_closed_form = RMSE(y_test, y_pred)\n",
    "rmse_closed_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 11: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_batch_training** : It fits a linear regression model using the batch gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate) and nEpoch (number of epochs) parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_batch_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_batch_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.01,nEpoch=1000, and save the returned results as betas_batch,cpu_time_batch.\n",
    "* Print betas_batch, cpu_time_batch\n",
    "* Call linear_regression_gd_batch_predict() function providing betas_batch,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_batch.\n",
    "* Print rmse_batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_gd_batch_training(X_train,y_train, alpha, nEpoch):\n",
    "    import random\n",
    "    random.seed(554433)\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "    start = perf_counter()\n",
    "    #@TODO: Your code goes here\n",
    "    \n",
    "    #first initialize betas to random \n",
    "    for feature in X_train:\n",
    "        beta = random.random()\n",
    "        betas.append(beta)\n",
    "    for epoch in range(nEpoch):\n",
    "        \n",
    "        mx = X_train.mul(betas)\n",
    "        y_pred = mx.sum(axis=1)            \n",
    "        \n",
    "        #m = len(X_train.columns) #number of variables \n",
    "        N = len(y_train) #number of samples\n",
    "        #diff = (y_train['BWEIGHT'].subtract(y_pred))\n",
    "        \n",
    "        betas = betas - (1.0/N)*alpha*(X_train.T.dot((y_train['BWEIGHT']-y_pred)))\n",
    "        #betas = betas - grad\n",
    "        \n",
    "    end = perf_counter()\n",
    "    cpu_time = end-start\n",
    "    return betas, cpu_time\n",
    "\n",
    "def linear_regression_gd_batch_predict(betas,X_test):\n",
    "    \n",
    "    #@TODO: Your code goes here\n",
    "    mx = X_test.mul(betas)\n",
    "    y_pred = mx.sum(axis=1)\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "betas_batch, cpu_time_batch = linear_regression_gd_batch_training(X_train_scaled_std,y_train,0.01,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.93855460000009\n",
      "Ones                  -1.500960e+05\n",
      "CARDIAC                2.404602e+07\n",
      "CERVIX                 6.314778e+07\n",
      "GAINED                 1.215494e+08\n",
      "onehotencoder__x1_S   -5.705516e+08\n",
      "TERMS                  2.887999e+08\n",
      "BDEAD                  5.210916e+07\n",
      "TOTALP                 1.834149e+08\n",
      "HYDRAM                -2.755272e+07\n",
      "onehotencoder__x1_N    8.502707e+08\n",
      "MAGE                   4.964832e+08\n",
      "onehotencoder__x1_O   -6.666683e+07\n",
      "HERPES                 4.701407e+07\n",
      "FEDUC                  7.988697e+08\n",
      "ACLUNG                -5.556613e+06\n",
      "RACEDAD                6.263436e+08\n",
      "RACEMOM                6.191519e+08\n",
      "onehotencoder__x0_O   -5.444407e+07\n",
      "VISITS                 3.619224e+08\n",
      "PINFANT                1.461908e+07\n",
      "UTERINE                4.444304e+06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cpu_time_batch)\n",
    "print(betas_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "y_pred = linear_regression_gd_batch_predict(betas_batch,X_test_scaled_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1.061464e+09\n",
      "1       -2.011646e+08\n",
      "2       -5.100815e+08\n",
      "3       -2.387565e+08\n",
      "4        9.596871e+08\n",
      "             ...     \n",
      "25345   -8.760098e+08\n",
      "25346   -3.438747e+09\n",
      "25347   -3.020123e+09\n",
      "25348    5.042240e+09\n",
      "25349    1.557218e+09\n",
      "Length: 25350, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2523280973.8430014\n"
     ]
    }
   ],
   "source": [
    "rmse_batch = RMSE(y_test, y_pred)\n",
    "print(rmse_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TASK 12:\n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_stochastic_training** : It fits a linear regression model using the stochastic gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate), nEpoch (number of epochs), nIteration (number of iterations) parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_stochastic_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_stochastic_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.01,nEpoch=50, nIteration=100 , and save the returned results as betas_stochastic,cpu_time_stochastic.\n",
    "* Print betas_stochastic, cpu_time_stochastic\n",
    "* Call linear_regression_gd_stochastic_predict() function providing betas_stochastic,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_stochastic.\n",
    "* Print rmse_stochastic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_gd_stochastic_training(X_train,y_train,alpha,nEpoch,nIteration):\n",
    "    import random\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    random.seed(554433)\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "    start = perf_counter()\n",
    "    \n",
    "    ## YOUR CODE HERE ###\n",
    "\n",
    "    #first initialize betas to random \n",
    "    for feature in X_train:\n",
    "        beta = random.random()\n",
    "        betas.append(beta)\n",
    "\n",
    "    for epoch in range(nEpoch):\n",
    "        print('EPOCH:', epoch)\n",
    "        \n",
    "         \n",
    "        N = len(y_train)\n",
    "\n",
    "        for it in range(nIteration):\n",
    "            #for 1 random samples calculate new weight using derivate equation \n",
    "\n",
    "            rand_index = np.random.randint(0,N)\n",
    "            X_rand = X_train.loc[[rand_index]]\n",
    "            y_train_rand = y_train.loc[[rand_index]]            \n",
    "            \n",
    "            mx = X_rand.mul(betas)\n",
    "            y_pred = mx.sum(axis=1)\n",
    "        \n",
    "            grad = (1.0/N)*alpha*(X_rand.T.dot((y_train_rand['BWEIGHT'].subtract(y_pred))))\n",
    "            betas = betas - grad\n",
    "                    \n",
    "    end = perf_counter()\n",
    "    cpu_time = end-start\n",
    "    \n",
    "    return betas, cpu_time\n",
    "\n",
    "def linear_regression_gd_stochastic_predict(betas, X_test):\n",
    "\n",
    "    y_pred = []\n",
    "    #@TODO: Your code goes here\n",
    "    mx = X_test.mul(betas)\n",
    "    y_pred = mx.sum(axis=1)    \n",
    "    \n",
    "    return y_pred\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "betas_stochastic,cpu_time_stochastic= linear_regression_gd_stochastic_training( X_train_scaled_std, y_train,0.01,50,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.63427369999954\n",
      "Ones                   0.090601\n",
      "CARDIAC                0.696778\n",
      "CERVIX                 0.442860\n",
      "GAINED                 0.237298\n",
      "onehotencoder__x1_S    0.155561\n",
      "TERMS                  0.844656\n",
      "BDEAD                  0.100189\n",
      "TOTALP                 0.646359\n",
      "HYDRAM                 0.305064\n",
      "onehotencoder__x1_N    0.120960\n",
      "MAGE                   0.737402\n",
      "onehotencoder__x1_O    0.180377\n",
      "HERPES                 0.806681\n",
      "FEDUC                  0.879577\n",
      "ACLUNG                 0.719055\n",
      "RACEDAD                0.940370\n",
      "RACEMOM                0.164970\n",
      "onehotencoder__x0_O    0.023022\n",
      "VISITS                 0.658191\n",
      "PINFANT                0.956643\n",
      "UTERINE                0.611618\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "print(cpu_time_stochastic)\n",
    "print(betas_stochastic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "y_pred = linear_regression_gd_stochastic_predict(betas_stochastic,X_test_scaled_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.084735\n",
       "1       -1.949991\n",
       "2       -2.076051\n",
       "3       -1.280553\n",
       "4        0.886265\n",
       "           ...   \n",
       "25345   -2.626254\n",
       "25346   -2.106334\n",
       "25347   -1.487163\n",
       "25348    1.820097\n",
       "25349    1.178226\n",
       "Length: 25350, dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "rmse_stochastic = RMSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.944411822870653\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "print(rmse_stochastic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 13: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_minibatch_training** : It fits a linear regression model using the minibatch gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate), nEpoch (number of epochs), nIteration (number of iterations), and batch_size parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_minibatch_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_minibatch_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.001,nEpoch=50, nIteration=1000,batch_size=32, and save the returned results as betas_minibatch,cpu_time_minibatch.\n",
    "* Print betas_minibatch, cpu_time_minibatch\n",
    "* Call linear_regression_gd_minibatch_predict() function providing betas_minibatch,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_minibatch.\n",
    "* Print rmse_minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_gd_minibatch_training(X_train,y_train,alpha,nEpoch, nIteration, batch_size):\n",
    "    import random\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    random.seed(554433)\n",
    "\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "\n",
    "    ## YOUR CODE HERE ###\n",
    "    \n",
    "    start = perf_counter()\n",
    "    \n",
    "    ## YOUR CODE HERE ###\n",
    "    #first initialize betas to random \n",
    "    for feature in X_train:\n",
    "        beta = random.random()\n",
    "        betas.append(beta)\n",
    "        \n",
    "    for epoch in range(nEpoch):\n",
    "        print('EPOCH:', epoch)\n",
    "        N = len(y_train)\n",
    "        \n",
    "        for it in range(nIteration):\n",
    "            #for n=batch_size random samples in each col calculate new weight using derivate equation \n",
    "            X_train_batch = X_train.sample(batch_size)\n",
    "            indices = X_train_batch.index\n",
    "            \n",
    "            temp_series = []\n",
    "            y_train_batch = pd.DataFrame()\n",
    "            \n",
    "            for index in indices: \n",
    "                row = y_train.loc[index]\n",
    "                temp_series.append(row)\n",
    "                \n",
    "            y_train_batch = pd.DataFrame(temp_series)\n",
    "            \n",
    "            \n",
    "            mx = X_train_batch.mul(betas)\n",
    "            y_pred = mx.sum(axis=1)\n",
    "        \n",
    "            grad = (1.0/N)*alpha*(X_train_batch.T.dot((y_train_batch['BWEIGHT'].subtract(y_pred))))\n",
    "            betas = betas - grad\n",
    "\n",
    "    end = perf_counter()\n",
    "    cpu_time = end-start\n",
    "    \n",
    "    \n",
    "    return betas,cpu_time\n",
    "\n",
    "def linear_regression_gd_minibatch_predict(betas,X_test):\n",
    "    y_pred = []\n",
    "    ## YOUR CODE HERE ###\n",
    "\n",
    "    mx = X_test.mul(betas)\n",
    "    y_pred = mx.sum(axis=1)    \n",
    "    \n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "betas_minibatch,cpu_time_minibatch = linear_regression_gd_minibatch_training(X_train_scaled_std, y_train,.001, 50, 1000, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856.0265894000004\n",
      "Ones                  -0.057050\n",
      "CARDIAC                0.712343\n",
      "CERVIX                 0.456196\n",
      "GAINED                 0.237546\n",
      "onehotencoder__x1_S    0.150968\n",
      "TERMS                  0.877301\n",
      "BDEAD                  0.107663\n",
      "TOTALP                 0.675623\n",
      "HYDRAM                 0.312877\n",
      "onehotencoder__x1_N    0.140118\n",
      "MAGE                   0.768145\n",
      "onehotencoder__x1_O    0.183656\n",
      "HERPES                 0.825115\n",
      "FEDUC                  0.907102\n",
      "ACLUNG                 0.734988\n",
      "RACEDAD                0.965977\n",
      "RACEMOM                0.186880\n",
      "onehotencoder__x0_O    0.023582\n",
      "VISITS                 0.673559\n",
      "PINFANT                0.976598\n",
      "UTERINE                0.625840\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "print(cpu_time_minibatch)\n",
    "print(betas_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "y_pred = linear_regression_gd_minibatch_predict(betas_minibatch,X_train_scaled_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        13.090243\n",
       "1        -1.339630\n",
       "2        -3.150180\n",
       "3        -3.902651\n",
       "4         0.378319\n",
       "           ...    \n",
       "76045    -2.048043\n",
       "76046    -1.653599\n",
       "76047    -1.107597\n",
       "76048    -0.536366\n",
       "76049    -0.282196\n",
       "Length: 76050, dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "rmse_minibatch = RMSE(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.120950138912287\n"
     ]
    }
   ],
   "source": [
    "print(rmse_minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 14:\n",
    "Given the 4 sets of results from the 4 experiments (from Tasks 10, 11, 12, 13) with closed form solution, batch gradient descent, stochastic gradient descent and mini-batch gradient descent, print a string from the set {\"closed-form\", \"batch-GD\", \"stochastic-GD\", \"minibatch-GD\"} that demonstrated the best predictive performance in terms of RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed-form 1.278774517544755\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "min_rmse_model = min(rmse_closed_form,rmse_batch,rmse_stochastic, rmse_minibatch)\n",
    "\n",
    "print('closed-form',min_rmse_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 15: \n",
    "Given the 4 sets of results from the 4 experiments (from Tasks 10, 11, 12, 13) with closed form solution, batch gradient descent, stochastic gradient descent and mini-batch gradient descent, print a string from the set {\"closed-form\", \"batch-GD\", \"stochastic-GD\", \"minibatch-GD\"} that demonstrated the least training cpu time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed-form 1.4654454000001351\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "min_cpu_time = min(cpu_time_closed_form,cpu_time_batch,cpu_time_stochastic,cpu_time_minibatch)\n",
    "\n",
    "print('closed-form',min_cpu_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 16: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively, \n",
    "* call your implementation of Task 12: stochastic gradient descent based linear regression for each of these learning rates: {0.0001, 0.001, 0.05, 0.01, 0.1, 1.0}\n",
    "    * Please use the nIteration (number of iterations), nEpoch (number of epoch) parameters in your implementation of the gradient descent algorithm.\n",
    "\n",
    "* For each of the linear regression model, using the computed beta values, predict the test samples provided in the \"X_test_scaled_std\" argument, and let's name your prediction \"y_pred\".\n",
    "* Compute Root Mean Squared Error (RMSE) of your prediction using the RMSE() function you defined in Task 10.\n",
    "* Finally, print the learning rate that shows the best test performance, and also print as a pandas dataframe named summary with 2 columns: {learning_rate, test_RMSE} containing RMSE's of the 6 linear regression models. Also, print the best performing learning rate.\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n",
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n",
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n",
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n",
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n",
      "EPOCH: 0\n",
      "EPOCH: 1\n",
      "EPOCH: 2\n",
      "EPOCH: 3\n",
      "EPOCH: 4\n",
      "EPOCH: 5\n",
      "EPOCH: 6\n",
      "EPOCH: 7\n",
      "EPOCH: 8\n",
      "EPOCH: 9\n",
      "EPOCH: 10\n",
      "EPOCH: 11\n",
      "EPOCH: 12\n",
      "EPOCH: 13\n",
      "EPOCH: 14\n",
      "EPOCH: 15\n",
      "EPOCH: 16\n",
      "EPOCH: 17\n",
      "EPOCH: 18\n",
      "EPOCH: 19\n",
      "EPOCH: 20\n",
      "EPOCH: 21\n",
      "EPOCH: 22\n",
      "EPOCH: 23\n",
      "EPOCH: 24\n",
      "EPOCH: 25\n",
      "EPOCH: 26\n",
      "EPOCH: 27\n",
      "EPOCH: 28\n",
      "EPOCH: 29\n",
      "EPOCH: 30\n",
      "EPOCH: 31\n",
      "EPOCH: 32\n",
      "EPOCH: 33\n",
      "EPOCH: 34\n",
      "EPOCH: 35\n",
      "EPOCH: 36\n",
      "EPOCH: 37\n",
      "EPOCH: 38\n",
      "EPOCH: 39\n",
      "EPOCH: 40\n",
      "EPOCH: 41\n",
      "EPOCH: 42\n",
      "EPOCH: 43\n",
      "EPOCH: 44\n",
      "EPOCH: 45\n",
      "EPOCH: 46\n",
      "EPOCH: 47\n",
      "EPOCH: 48\n",
      "EPOCH: 49\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "alpha = [0.0001, 0.001, 0.05, 0.01, 0.1, 1.0]\n",
    "rmses = []\n",
    "\n",
    "for a in alpha:\n",
    "    betas, cpu_time = linear_regression_gd_stochastic_training(X_train_scaled_std,y_train,a,50,100)\n",
    "    y_pred = linear_regression_gd_stochastic_predict(betas,X_test_scaled_std)\n",
    "    rmse = RMSE(y_test, y_pred)\n",
    "    temp_object = (a,rmse)\n",
    "    rmses.append(temp_object)\n",
    "    \n",
    "rmse_df = pd.DataFrame(rmses, columns =['learning_rate', 'test_RMSE'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>7.938791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>7.939305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>7.966681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>7.944332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>7.995089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  test_RMSE\n",
       "0         0.0001   7.938791\n",
       "1         0.0010   7.939305\n",
       "2         0.0500   7.966681\n",
       "3         0.0100   7.944332\n",
       "4         0.1000   7.995089"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   learning_rate  test_RMSE\n",
      "0         0.0001   7.938791\n"
     ]
    }
   ],
   "source": [
    "minidx = rmse_df[['test_RMSE']].idxmin()\n",
    "print(rmse_df.loc[minidx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 17:\n",
    "* Utilizing the best trained linear regression model (so far), predict the target for each of the samples in the judge_dataset.\n",
    "    * I believe you will not forget to do the following before call in the prediction algorithm:\n",
    "        - Save the ID values of the judge dataset into ID_judge and drop it from the judge dataframe.\n",
    "        - Perform onehot encoding using the same encoder you used to encode X_test (Task 4). \n",
    "        - keep only the same top 20 variables as you did in Task 7. \n",
    "        - scale the input variables based on the same metrics you used to scale the training dataset (Task 9). \n",
    "    * Now, call the prediction function of that model to obtain y_pred.\n",
    "    * Prepare and print as a pandas dataframe having columns: {ID, BWEIGHT}, where ID will the ID of the judge sample, and BWEIGHT is the corresponding y_pred value from your model prediction.\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>LOUTCOME</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>HISPMOM</th>\n",
       "      <th>HISPDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>DRINKNUM</th>\n",
       "      <th>ANEMIA</th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  \\\n",
       "0        1    1        1    30      70      11    26     14     16       4   \n",
       "1        2    2        2    21      36      15    18      9     12       1   \n",
       "2        3    2        1    22      18      10    25     12     12       5   \n",
       "3        4    2        1    24      25      10    22     12     11       4   \n",
       "4        5    2        1    24      38      15    26     12     12       1   \n",
       "...    ...  ...      ...   ...     ...     ...   ...    ...    ...     ...   \n",
       "1995  1996    2        1    21      17       9    21     13     12       1   \n",
       "1996  1997    1        1    27      20      10    26     16     16       2   \n",
       "1997  1998    1        1    29      25      17    27     12     12       2   \n",
       "1998  1999    1        1    37      29      11    34     12     16       2   \n",
       "1999  2000    1        2    30      20      13    27     12     13       2   \n",
       "\n",
       "      BDEAD  TERMS  LOUTCOME  WEEKS  RACEMOM  RACEDAD HISPMOM HISPDAD  CIGNUM  \\\n",
       "0         0      3         9     36        1        1       N       N       0   \n",
       "1         0      0         9     41        3        3       N       N       0   \n",
       "2         0      3         2     39        1        1       S       N      20   \n",
       "3         0      0         1     39        1        1       N       N       0   \n",
       "4         0      0         9     38        1        1       N       N       0   \n",
       "...     ...    ...       ...    ...      ...      ...     ...     ...     ...   \n",
       "1995      0      0         9     35        1        1       N       N       0   \n",
       "1996      0      0         1     39        1        1       N       N       0   \n",
       "1997      0      0         1     40        1        1       N       N       0   \n",
       "1998      0      0         1     38        1        1       N       N       0   \n",
       "1999      0      0         1     34        1        1       N       N       5   \n",
       "\n",
       "      DRINKNUM  ANEMIA  CARDIAC  ACLUNG  DIABETES  HERPES  HYDRAM  HEMOGLOB  \\\n",
       "0            0       0        0       0         0       0       0         0   \n",
       "1            0       0        0       1         0       0       0         1   \n",
       "2            0       1        0       1         0       0       0         0   \n",
       "3            0       0        0       0         0       0       0         0   \n",
       "4            0       0        0       0         0       0       0         0   \n",
       "...        ...     ...      ...     ...       ...     ...     ...       ...   \n",
       "1995         0       0        0       0         0       0       0         0   \n",
       "1996         0       0        0       0         0       0       0         0   \n",
       "1997         0       0        0       0         0       0       0         0   \n",
       "1998         0       0        0       0         0       0       0         0   \n",
       "1999         0       0        0       0         0       0       0         0   \n",
       "\n",
       "      HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  RENAL  RHSEN  \\\n",
       "0           0        0       0       0        0        0      0      0   \n",
       "1           0        0       0       0        0        0      0      0   \n",
       "2           0        0       0       0        0        0      0      0   \n",
       "3           0        0       0       0        0        0      0      0   \n",
       "4           0        1       0       0        0        0      0      0   \n",
       "...       ...      ...     ...     ...      ...      ...    ...    ...   \n",
       "1995        0        0       0       0        0        0      0      0   \n",
       "1996        0        0       0       0        0        0      1      0   \n",
       "1997        0        0       0       0        0        0      0      0   \n",
       "1998        0        0       0       0        0        0      0      0   \n",
       "1999        0        0       0       0        0        0      0      0   \n",
       "\n",
       "      UTERINE  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "1995        0  \n",
       "1996        0  \n",
       "1997        0  \n",
       "1998        0  \n",
       "1999        0  \n",
       "\n",
       "[2000 rows x 36 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 35)\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "#Save the ID values of the judge dataset into ID_judge and drop it from the judge dataframe.\n",
    "\n",
    "original_df = judge_dataset.copy()\n",
    "Id_judge = judge_dataset['ID']\n",
    "X_test = judge_dataset.drop(['ID'], axis=1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Perform onehot encoding using the same encoder you used to encode X_test (Task 4).\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = X_test.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = X_test.columns[categorical_feature_mask].tolist()\n",
    "cat_columns_idx = [X_test.columns.get_loc(col) \n",
    "                   for col in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_cols),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "X_test_ohe = pd.DataFrame(column_trans.fit_transform(X_test),columns=column_trans.get_feature_names())\n",
    "missing = X_test_ohe.isnull().sum()\n",
    "\n",
    "X_test_ohe_imputed = X_test_ohe.copy()\n",
    "missing_cols = []\n",
    "for item in missing.iteritems(): \n",
    "    if item[1] != 0:\n",
    "        missing_cols.append(item[0])\n",
    "        \n",
    "print('Columns with missing values:')\n",
    "print(missing_cols)  \n",
    "\n",
    "for col in missing_cols:\n",
    "    X_test_ohe_imputed[col].fillna(value=(X_test_ohe[col].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only the same top 20 variables as you did in Task 7.\n",
    "X_test_t20 = getX_t20(top20_df,X_test_ohe_imputed)\n",
    "X_test_t20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <th>HERPES</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ACLUNG</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>2.900081</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>3.220394</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.273158</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.112509</td>\n",
       "      <td>0.384771</td>\n",
       "      <td>-0.110208</td>\n",
       "      <td>-0.359674</td>\n",
       "      <td>-0.346231</td>\n",
       "      <td>-0.059265</td>\n",
       "      <td>-0.388540</td>\n",
       "      <td>-0.067233</td>\n",
       "      <td>-0.050063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>0.416478</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>-0.489025</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>-0.891647</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-1.609711</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.112509</td>\n",
       "      <td>-1.364187</td>\n",
       "      <td>9.073772</td>\n",
       "      <td>1.120466</td>\n",
       "      <td>1.066958</td>\n",
       "      <td>-0.059265</td>\n",
       "      <td>0.697905</td>\n",
       "      <td>-0.067233</td>\n",
       "      <td>-0.050063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>-0.898370</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>3.220394</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>1.690966</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.440227</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.112509</td>\n",
       "      <td>-0.314812</td>\n",
       "      <td>9.073772</td>\n",
       "      <td>-0.359674</td>\n",
       "      <td>-0.346231</td>\n",
       "      <td>-0.059265</td>\n",
       "      <td>-0.660151</td>\n",
       "      <td>-0.067233</td>\n",
       "      <td>-0.050063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>-0.387040</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>-0.489025</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.941434</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.112509</td>\n",
       "      <td>-0.314812</td>\n",
       "      <td>-0.110208</td>\n",
       "      <td>-0.359674</td>\n",
       "      <td>-0.346231</td>\n",
       "      <td>-0.059265</td>\n",
       "      <td>-0.660151</td>\n",
       "      <td>-0.067233</td>\n",
       "      <td>-0.050063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>0.562572</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>-0.489025</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>-0.891647</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.273158</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.112509</td>\n",
       "      <td>-0.314812</td>\n",
       "      <td>-0.110208</td>\n",
       "      <td>-0.359674</td>\n",
       "      <td>-0.346231</td>\n",
       "      <td>-0.059265</td>\n",
       "      <td>0.697905</td>\n",
       "      <td>-0.067233</td>\n",
       "      <td>-0.050063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CARDIAC   CERVIX    GAINED  onehotencoder__x1_S     TERMS     BDEAD  \\\n",
       "0 -0.054855 -0.08396  2.900081            -0.189031  3.220394 -0.095783   \n",
       "1 -0.054855 -0.08396  0.416478            -0.189031 -0.489025 -0.095783   \n",
       "2 -0.054855 -0.08396 -0.898370            -0.189031  3.220394 -0.095783   \n",
       "3 -0.054855 -0.08396 -0.387040            -0.189031 -0.489025 -0.095783   \n",
       "4 -0.054855 -0.08396  0.562572            -0.189031 -0.489025 -0.095783   \n",
       "\n",
       "     TOTALP    HYDRAM  onehotencoder__x1_N      MAGE  onehotencoder__x1_O  \\\n",
       "0  1.045313 -0.114766             0.441297 -0.273158            -0.031639   \n",
       "1 -0.891647 -0.114766             0.441297 -1.609711            -0.031639   \n",
       "2  1.690966 -0.114766             0.441297 -0.440227            -0.031639   \n",
       "3  1.045313 -0.114766             0.441297 -0.941434            -0.031639   \n",
       "4 -0.891647 -0.114766             0.441297 -0.273158            -0.031639   \n",
       "\n",
       "     HERPES     FEDUC    ACLUNG   RACEDAD   RACEMOM  onehotencoder__x0_O  \\\n",
       "0 -0.112509  0.384771 -0.110208 -0.359674 -0.346231            -0.059265   \n",
       "1 -0.112509 -1.364187  9.073772  1.120466  1.066958            -0.059265   \n",
       "2 -0.112509 -0.314812  9.073772 -0.359674 -0.346231            -0.059265   \n",
       "3 -0.112509 -0.314812 -0.110208 -0.359674 -0.346231            -0.059265   \n",
       "4 -0.112509 -0.314812 -0.110208 -0.359674 -0.346231            -0.059265   \n",
       "\n",
       "     VISITS   PINFANT   UTERINE  \n",
       "0 -0.388540 -0.067233 -0.050063  \n",
       "1  0.697905 -0.067233 -0.050063  \n",
       "2 -0.660151 -0.067233 -0.050063  \n",
       "3 -0.660151 -0.067233 -0.050063  \n",
       "4  0.697905 -0.067233 -0.050063  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale the input variables based on the same metrics you used to scale the training dataset (Task 9).\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_test_t20)\n",
    "X_test_scaled_std = scaler.transform(X_test_t20)\n",
    "X_test_scaled_std = pd.DataFrame(X_test_scaled_std, columns = X_test_t20.columns)\n",
    "X_test_scaled_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test_scaled_std.insert(loc=0, column='Ones', value =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# call the prediction function of that model to obtain y_pred.\n",
    "y_pred = linear_regression_closed_form_predict(betas_closed_form,X_test_scaled_std)\n",
    "y_pred = pd.DataFrame(y_pred, columns = ['BWEIGHT'])\n",
    "Id_judge = pd.DataFrame(Id_judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = Id_judge.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.660574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.116029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.751935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.157561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.446578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>6.811875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>7.065015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>7.380780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>7.273310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>7.131983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID   BWEIGHT\n",
       "0        1  7.660574\n",
       "1        2  7.116029\n",
       "2        3  6.751935\n",
       "3        4  7.157561\n",
       "4        5  7.446578\n",
       "...    ...       ...\n",
       "1995  1996  6.811875\n",
       "1996  1997  7.065015\n",
       "1997  1998  7.380780\n",
       "1998  1999  7.273310\n",
       "1999  2000  7.131983\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#{ID, BWEIGHT}\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Graduate Students only\n",
    "## Task 18:\n",
    "Bring your best model and submit your solution at https://www.kaggle.com/c/birth-weight-prediction\n",
    "Submit multiple entries. Demonstrate your effort by pushing yourself to improve your own score or beat other submissions (if any available) until the deadline and document your scores and list what changes you made in your submitted solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "y_pred.to_csv('y_pred.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "I attempted to improve my regression by training the model on only the top 10 correlated variables intead of the top 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 10)\n",
      "(76050, 10)\n"
     ]
    }
   ],
   "source": [
    "#keep only the same top 20 variables as you did in Task 7.\n",
    "X_test_t10 = getX_t20(top10_df,X_test_ohe_imputed)\n",
    "print(X_test_t10.shape)\n",
    "\n",
    "X_train_t10 = getX_t20(top10_df,X_train_ohe_imputed)\n",
    "print(X_train_t10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDIAC</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <th>TERMS</th>\n",
       "      <th>BDEAD</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <th>MAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>2.900081</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>3.220394</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.273158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>0.416478</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>-0.489025</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>-0.891647</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-1.609711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>-0.898370</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>3.220394</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>1.690966</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.440227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>-0.387040</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>-0.489025</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.941434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.054855</td>\n",
       "      <td>-0.08396</td>\n",
       "      <td>0.562572</td>\n",
       "      <td>-0.189031</td>\n",
       "      <td>-0.489025</td>\n",
       "      <td>-0.095783</td>\n",
       "      <td>-0.891647</td>\n",
       "      <td>-0.114766</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>-0.273158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CARDIAC   CERVIX    GAINED  onehotencoder__x1_S     TERMS     BDEAD  \\\n",
       "0 -0.054855 -0.08396  2.900081            -0.189031  3.220394 -0.095783   \n",
       "1 -0.054855 -0.08396  0.416478            -0.189031 -0.489025 -0.095783   \n",
       "2 -0.054855 -0.08396 -0.898370            -0.189031  3.220394 -0.095783   \n",
       "3 -0.054855 -0.08396 -0.387040            -0.189031 -0.489025 -0.095783   \n",
       "4 -0.054855 -0.08396  0.562572            -0.189031 -0.489025 -0.095783   \n",
       "\n",
       "     TOTALP    HYDRAM  onehotencoder__x1_N      MAGE  \n",
       "0  1.045313 -0.114766             0.441297 -0.273158  \n",
       "1 -0.891647 -0.114766             0.441297 -1.609711  \n",
       "2  1.690966 -0.114766             0.441297 -0.440227  \n",
       "3  1.045313 -0.114766             0.441297 -0.941434  \n",
       "4 -0.891647 -0.114766             0.441297 -0.273158  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale the input variables based on the same metrics you used to scale the training dataset (Task 9).\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_test_t10)\n",
    "X_test_scaled_std = scaler.transform(X_test_t10)\n",
    "X_test_scaled_std = pd.DataFrame(X_test_scaled_std, columns = X_test_t10.columns)\n",
    "X_test_scaled_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train_t10)\n",
    "X_train_scaled_std = scaler.transform(X_train_t10)\n",
    "X_train_scaled_std = pd.DataFrame(X_train_scaled_std, columns = X_train_t10.columns)\n",
    "X_train_scaled_std.head()\n",
    "\n",
    "X_train_scaled_std.insert(loc=0, column='Ones', value =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test_scaled_std.insert(loc=0, column='Ones', value =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#retrain model on top 10 correlations \n",
    "betas_closed_form,cpu_time_closed_form = linear_regression_closed_form_training(X_train_scaled_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.25699786e+00]\n",
      " [-1.82161831e-03]\n",
      " [-8.55326857e-02]\n",
      " [ 2.48730433e-01]\n",
      " [-1.57224437e-02]\n",
      " [-7.94102558e-02]\n",
      " [-4.58827306e-02]\n",
      " [ 5.75399190e-02]\n",
      " [-6.45615257e-02]\n",
      " [-5.97011242e-02]\n",
      " [ 1.08702760e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(betas_closed_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# call the prediction function of that model to obtain y_pred.\n",
    "y_pred = linear_regression_closed_form_predict(betas_closed_form,X_test_scaled_std)\n",
    "y_pred = pd.DataFrame(y_pred, columns = ['BWEIGHT'])\n",
    "Id_judge = pd.DataFrame(Id_judge)\n",
    "y_pred = Id_judge.join(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.748770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.168849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.822969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.153085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.350474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>6.878119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>7.060582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>7.169588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>7.369390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>7.078743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID   BWEIGHT\n",
       "0        1  7.748770\n",
       "1        2  7.168849\n",
       "2        3  6.822969\n",
       "3        4  7.153085\n",
       "4        5  7.350474\n",
       "...    ...       ...\n",
       "1995  1996  6.878119\n",
       "1996  1997  7.060582\n",
       "1997  1998  7.169588\n",
       "1998  1999  7.369390\n",
       "1999  2000  7.078743\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred.to_csv('y_pred2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
